# config.ini

[model]
# Model selection and configuration
# Options for model_path:
#   - "auto": Automatically select based on available resources
#   - "openai/whisper-tiny": Fastest, lowest accuracy (1GB VRAM)
#   - "openai/whisper-base": Balanced (2GB VRAM)
#   - "openai/whisper-small": Good accuracy (4GB VRAM)
#   - "openai/whisper-medium": High accuracy (8GB VRAM)
#   - "openai/whisper-large": Best accuracy (16GB VRAM)
model_path = auto

# Device selection:
#   - "auto": Automatically detect the best available device
#   - "cuda": Force NVIDIA GPU usage
#   - "mps": Force Apple Silicon GPU usage
#   - "cpu": Force CPU usage
device = auto

# Model-specific settings
beam_size = 5              # Number of beams for beam search (higher = better accuracy, slower processing)
language = en              # Target language (e.g., en, fr, de)
task = transcribe          # Task type: transcribe or translate
compute_type = float32     # Computation type: float32, float16, or bfloat16

# Model caching settings
cache_dir = models         # Directory to store downloaded models
use_cached = true          # Use cached models if available
force_download = false     # Force download even if cached

# Model display settings
show_chunk_info = true     # Display chunk size information in model configuration
show_hardware_info = true  # Display hardware details in system configuration

# Model hierarchy settings
high_model_name = openai/whisper-medium
high_min_memory = 12000000000    # Minimum memory for high-end models (12GB)
high_chunk_size = 32000          # Chunk size for high-end models (2 seconds at 16kHz)
high_min_chunk_size = 4000       # Minimum chunk size for high-end models (0.25 seconds)

medium_model_name = openai/whisper-small
medium_min_memory = 8000000000    # Minimum memory for medium-end models (8GB)
medium_chunk_size = 24000          # Chunk size for medium-end models (1.5 seconds at 16kHz)
medium_min_chunk_size = 4000       # Minimum chunk size for medium-end models (0.25 seconds)

low_model_name = openai/whisper-base
low_min_memory = 4000000000       # Minimum memory for low-end models (4GB)
low_chunk_size = 16000             # Chunk size for low-end models (1 second at 16kHz)
low_min_chunk_size = 4000          # Minimum chunk size for low-end models (0.25 seconds)

tiny_model_name = openai/whisper-tiny
tiny_min_memory = 2000000000      # Minimum memory for tiny models (2GB)
tiny_chunk_size = 8000             # Chunk size for tiny models (0.5 seconds at 16kHz)
tiny_min_chunk_size = 4000         # Minimum chunk size for tiny models (0.25 seconds)

[audio]
# Audio input configuration
input_sample_rate = 48000                 # Hardware input sample rate
processing_sample_rate = 16000            # Internal processing sample rate
resampling_enabled = true                # Enable automatic resampling
channels = 1                   # Number of audio channels (1 = mono, 2 = stereo)
chunk_size = 4000              # Size of audio chunks to process
input_device = default         # Input device name or "default"

# Audio Processing Settings
audio_scaling_factor = 32767    # Scaling factor for int16 conversion
normalization_enabled = true    # Enable audio normalization
dc_offset_removal = true        # Enable DC offset removal

# Voice Activity Detection (VAD) Settings
enabled = true                          # Enable/disable VAD
aggressiveness = 1                      # VAD aggressiveness level (0-3)
frame_duration_ms = 30                  # VAD frame duration in milliseconds
padding_duration_ms = 500               # Padding duration for VAD segments
speech_threshold = 0.001               # Threshold for speech detection
min_speech_duration_ms = 100            # Minimum duration to consider as speech (milliseconds)
max_silence_duration_ms = 1000          # Maximum silence duration within speech (milliseconds)
vad_min_speech_frames = 2                # Minimum frames to consider as speech
vad_initial_speech_probability = 0.0     # Initial probability of speech
vad_speech_probability_threshold = 0.4    # Threshold for speech probability
vad_probability_decay = 0.7              # Decay factor for speech probability
vad_probability_update = 0.3             # Update factor for speech probability
vad_silence_threshold_ratio = 0.3        # Ratio for silence detection
vad_min_speech_duration = 0.5            # Minimum speech duration in seconds

# Time unit conversions
ms_to_sec_factor = 1000                  # Conversion factor from milliseconds to seconds

# VAD Frame Calculations
vad_frame_size_factor = 1.0              # Factor for frame size calculation
vad_padding_size_factor = 1.0            # Factor for padding size calculation
vad_silence_frames_factor = 1.0          # Factor for silence frames calculation

# Frame processing
frame_pack_format = h                    # Format for struct.pack (h=short, i=int, etc.)

# VAD Confidence values
vad_speech_confidence = 1.0              # Confidence value for speech detection
vad_silence_confidence = 0.0             # Confidence value for silence detection

# VAD Frame Adjustments
vad_speech_frame_decrease = 1.0          # Rate to decrease speech frames
vad_silence_frame_decrease = 1.0         # Rate to decrease silence frames

[buffer]
# Core buffer settings
max_buffer_size = 160000                 # Maximum buffer size in samples
min_buffer_size = 80000                  # Minimum buffer size in samples
chunk_size = 4000                        # Processing chunk size
min_chunk_size = 2000                    # Minimum chunk size
overlap_size = 16000                     # Overlap between chunks

# Queue settings
max_queue_size = 10                      # Maximum size for all queues
transcription_queue_size = 10            # Size of transcription queue
output_queue_size = 10                   # Size of output queue
silence_threshold_seconds = 0.3          # Silence threshold in seconds

# Buffer Management Settings
min_chunk_interval = 0.5                  # Minimum time between chunks (seconds)
buffer_maxlen = 80000                     # Maximum buffer length
max_chunks_memory = 3                     # Maximum chunks to keep in memory
maintain_overlap = true                   # Keep overlap portion when clearing
clear_on_reset = true                     # Clear all data on reset

[transcription]
# Transcription processing settings
confidence_threshold = 0.5                # Minimum confidence score to accept transcription
max_segment_duration = 10.0               # Maximum duration of a single segment (seconds)
similarity_threshold = 0.85               # Threshold for detecting duplicate transcriptions
min_words_per_segment = 3                 # Minimum words to consider a valid segment
max_words_per_segment = 50                # Maximum words per segment

# Post-processing options
remove_filler_words = true                # Remove filler words like "um", "uh", etc.
capitalize_sentences = true               # Capitalize the beginning of sentences
add_punctuation = true                    # Add punctuation using model predictions
merge_short_segments = true               # Merge very short segments

[processing]
# Text processing settings
buffer_time = 2.0                         # Time to accumulate text before processing
min_buffer_size = 5                       # Minimum number of text segments to process
max_buffer_size = 20                      # Maximum number of text segments to process
parallel_processing = true                # Enable parallel text processing
num_workers = 2                           # Number of parallel workers

[logging]
# Logging configuration
level = INFO                              # Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
max_file_size = 10                        # Maximum log file size in MB
backup_count = 5                          # Number of backup files to keep
log_format = detailed                     # Log format: simple, detailed, or json
include_timestamps = true                 # Include timestamps in logs
log_to_console = true                     # Output logs to console
log_to_file = true                        # Output logs to file

[display]
# Display and output settings
show_confidence = false                   # Show confidence scores
show_timestamps = true                    # Show timestamps
colored_output = true                     # Use colored output in terminal
live_wpm = true                           # Show words per minute in real-time
show_speaker_changes = true               # Attempt to detect and show speaker changes
progress_bar = true                       # Show progress bar during processing

[advanced]
# Advanced settings (use with caution)
use_gpu_acceleration = auto                # Use GPU acceleration when available
gpu_memory_fraction = 0.7                  # Fraction of GPU memory to use
batch_size = 1                             # Batch size for processing
thread_priority = normal                   # Thread priority (low, normal, high)
enable_optimization = true                 # Enable performance optimizations
debug_mode = false                        # Enable debug mode

[device]
# Memory allocation settings
cpu_memory_fraction = 0.5                   # Fraction of system RAM to use for CPU processing
mps_memory_fraction = 0.7                   # Fraction of system RAM to use for Apple Silicon GPU
cuda_memory_limit = 0.9                     # Fraction of VRAM to use for NVIDIA GPU

[audio_stream]
# Audio stream settings
default_sample_rate = 48000                 # Default sample rate in Hz
default_channels = 2                       # Default number of channels (2=stereo)
default_chunk_size = 4000                  # Default chunk size
queue_timeout = 0.1                        # Queue timeout in seconds
audio_level_threshold = 0.01               # Threshold for audio level detection
format = float32                           # Audio format (float32, int16, etc.)

# Device settings
device_name = BlackHole 2ch                 # Target audio device name
show_device_scan = true                    # Show device scanning messages
show_status = true                         # Show audio stream status
show_detection = true                      # Show audio detection messages

[pipeline_workers]
# Transcription Worker Settings
sampling_rate = 16000                       # Audio sampling rate for model input
max_length = 448                           # Maximum length for model generation
num_beams = 5                              # Number of beams for beam search
no_repeat_ngram_size = 3                   # N-gram repetition prevention size
default_confidence = 0.95                  # Default confidence score for transcriptions
normalize_audio = true                     # Whether to normalize audio before processing

# Text Processing Worker Settings
queue_timeout = 0.1                        # Timeout for queue operations
buffer_time = 2.0                          # Time to accumulate text before processing
min_buffer_size = 5                        # Minimum size of text buffer before processing
clean_text = true                          # Enable text cleaning
log_transcriptions = true                  # Enable transcription logging

[realtime_handler]
# SpaCy configuration
spacy_model = en_core_web_sm                # SpaCy model to use
disable_components = ner                    # Components to disable (comma-separated)
enable_sentencizer = true                   # Enable sentence segmentation

# Word validation
enable_word_validation = true               # Enable word validation
min_word_length = 2                        # Minimum length for word consideration

# Common prefixes and suffixes (comma-separated)
common_prefixes = un,re,in,dis,pre,post,non,anti,semi,over
common_suffixes = ing,ed,s,ly,tion,ment,ness,able,ible,ful

# Text processing
strip_text = true                           # Strip whitespace from text
combine_partial_words = true                # Combine partial words

[text_processing]
# Similarity checking
similarity_threshold = 0.85                  # Threshold for detecting similar text

# Text cleaning
strip_transcription_prefix = true            # Remove "Transcription:" prefix
uppercase_text = true                        # Convert text to uppercase
preserve_chars = ABCDEFGHIJKLMNOPQRSTUVWXYZ-\s''        # Characters to preserve: uppercase, hyphen, whitespace, single quotes
min_word_length = 1                          # Minimum word length to keep
max_repetitions = 1                          # Maximum allowed word repetitions

# Special words
allowed_single_chars = A,I                   # Single characters to preserve

# Sentence completion
sentence_end_chars = .,!,?,;                 # Characters that end sentences
ending_phrases = OKAY,RIGHT,YOU KNOW,YOU SEE,THANK YOU  # Phrases that can end sentences

# Artifacts to remove (comma-separated pairs of pattern:replacement)
artifacts = UM:,UH:,HMM:,AH:,ER:,LIKE\s+(?=\bLIKE\b):

# Timestamp format
timestamp_format = %%H:%%M:%%S                 # Format for timestamp in output (%H=hour, %M=minute, %S=second)

[vad]
# Core VAD settings
enabled = true
aggressiveness = 1
frame_duration_ms = 30
padding_duration_ms = 500

# Speech detection
speech_threshold = 0.0005
min_speech_duration_ms = 100
max_silence_duration_ms = 1000

# Probability settings
initial_probability = 0.0
probability_threshold = 0.4
probability_decay = 0.7
probability_update = 0.3
silence_probability = 0.3

# VAD confidence values
speech_confidence = 1.0                    # Confidence value for speech detection
silence_confidence = 0.0                   # Confidence value for silence detection